🤖 AI最新ニュースダイジェスト 🤖
2025年08月20日 12:54

【1】Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13167
📅 2025年08月20日
💡 この論文は、大規模言語モデル（LLM）を用いた新しい推論パラダイム「Chain-of-Agents (CoA)」を紹介しています。CoAは、複数のツールとエージェントを活用して複雑な問題を解決するマルチエージェントシステムを、単一のモデル内で実現します。研究者たちは、マルチエージェント蒸留とエージェント型強化学習を用いて、CoAの能力を向上させ、Agent Foundation Models (AFM)を開発しました。AF

【2】Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13171
📅 2025年08月20日
💡 この論文は、大規模言語モデル（LLM）におけるコンテキスト管理の限界を克服するために、人間の認知メカニズムを模倣した「Cognitive Workspace」という新しいパラダイムを提案しています。従来の受動的な情報検索システムとは異なり、Cognitive Workspaceは、能動的なメモリ管理、階層的な認知バッファ、タスク主導のコンテキスト最適化を通じて、LLMの認知能力を拡張することを目指しています。実験結果では、

【3】Search-Time Data Contamination (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13180
📅 2025年08月20日
💡 この論文は、検索ベースのLLMエージェントの評価における「検索時データ汚染（STC）」という新たな問題点を指摘しています。STCは、エージェントがオンライン検索を通じて評価データ（質問と回答）を直接取得し、推論や理解をせずに回答をコピーしてしまう現象です。研究者らは、HuggingFaceなどのプラットフォームが検索結果に現れ、評価データが漏洩していることを発見し、ベンチマークの信頼

【4】"DIVE" into Hydrogen Storage Materials Discovery with AI Agents (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13251
📅 2025年08月20日
💡 この論文は、AIエージェントを活用して水素貯蔵材料の発見を加速させる新しいアプローチ「DIVE」を紹介しています。DIVEは、科学論文の図表から実験データを体系的に抽出し、LLM（大規模言語モデル）ベースのAIエージェントによる自動材料設計を可能にします。DIVEは、既存のモデルよりも大幅に高い精度でデータ抽出を行い、水素貯蔵材料の迅速な逆設計を実現しました。この技術は、

【5】HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13333
📅 2025年08月20日
💡 この論文は、大規模言語モデル（LLM）を活用した自動ヒューリスティック設計（AHD）を改善する新しいフレームワーク「HiFo-Prompt」を紹介しています。HiFo-Promptは、探索と活用のバランスを調整する「Foresight」と、過去の成功から学び再利用可能な設計原則を抽出する「Hindsight」という2つのプロンプティング戦略を組み合わせることで、LLMが自身の経験から学習できるようにします。その結果

【6】LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13371
📅 2025年08月20日
💡 この論文は、自律システムにおける計画能力を向上させるための新しいニューロシンボリックフレームワーク「LOOP」を紹介しています。LOOPは、ニューラルコンポーネントとシンボリックコンポーネントを反復的に連携させ、計画を洗練させることで、従来のニューラルプランニングの限界と古典的なプランナーの柔軟性の欠如を克服します。LOOPは、空間関係、マルチエージェント検証、階層的分解、因果メモリ

【7】Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13579
📅 2025年08月20日
💡 この論文は、大規模言語モデル（LLM）の電子健康記録（EHR）推論能力を向上させるための新しいフレームワーク、EAG-RLを提案しています。EAG-RLは、専門家の注意誘導を用いた強化学習を通じて、LLMのEHRデータ理解と予測能力を強化します。実験結果は、EAG-RLがLLMのEHR推論能力を大幅に向上させ、臨床予測タスクにおける実用的な可能性

【8】Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13678
📅 2025年08月20日
💡 この論文は、大規模言語モデル（LLM）の推論能力を向上させるためのニューロシンボリックAIアプローチに焦点を当てています。ニューロシンボリックAIは、LLMと記号処理を組み合わせることで、LLMの推論能力を強化する有望な方法として注目されています。論文では、Symbolic->LLM、LLM->Symbolic、LLM+Symbolicの3つの視点から、この分野の最近の

【9】CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13721
📅 2025年08月20日
💡 この論文は、大規模言語モデル（LLM）エージェントの協調タスクにおけるパフォーマンスを向上させるための新しいフレームワーク、CausalPlanを紹介しています。CausalPlanは、因果関係に基づく推論をLLMの計画プロセスに組み込み、エージェントの行動が因果的に整合するように設計されています。このフレームワークは、行動間の因果関係を学習する構造的因果行動（SCA）モデルを使用し、LLMが生成

【10】Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2508.13754
📅 2025年08月20日
💡 この論文は、医療意思決定を支援するために、複数の大規模言語モデル（LLM）の専門知識を活かした新しいフレームワーク「EMRC」を提案しています。EMRCは、LLMの専門知識を評価し、最適なLLMを動的に選択して協調させることで、診断の精度と信頼性を向上させます。実験結果は、EMRCが既存の単一および複数LLM手法を上回り、特にMMLU-Pro-

---
合計 91 件のAI関連ニュースが見つかりました。