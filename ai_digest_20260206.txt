🤖 AI最新ニュースダイジェスト 🤖
2026年02月06日 13:18

【1】Knowledge Model Prompting Increases LLM Performance on Planning Tasks (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.03900
📅 2026年02月06日
💡 この論文は、大規模言語モデル（LLM）の計画タスクにおける推論能力を向上させるために、タスク-方法-知識（TMK）フレームワークを活用しています。TMKは、因果関係、目的論、階層構造を捉え、複雑な問題をより管理しやすいサブタスクに分解するのに役立ちます。PlanBenchベンチマークのBlocksworldドメインでの実験結果は、TMKプロンプティングがLLMの精度

【2】Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.03950
📅 2026年02月06日
💡 この論文は、大規模言語モデル（LLM）の数学的推論能力を向上させる新しい手法「Iteratively Improved Program Construction (IIPC)」を提案しています。IIPCは、プログラム的な推論チェーンを反復的に改善し、実行フィードバックとLLMのChain-of-thought能力を組み合わせることで、より正確で修正可能な推論プロセスを実現します。これにより、既存のLLMベースの数学問題解決システムよりも優れた性能を発揮し

【3】AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.03955
📅 2026年02月06日
💡 AgentArkは、複数エージェントの知能を単一のLLM（大規模言語モデル）に凝縮する新しいフレームワークです。この手法は、複数エージェントシステムの優れた推論能力を維持しつつ、計算コストを大幅に削減します。AgentArkは、推論能力を向上させるファインチューニング、軌道ベースのデータ拡張、プロセス認識蒸留という3つの戦略を用いて、単一エージェントの効率性と複数エ

【4】Active Epistemic Control for Query-Efficient Verified Planning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.03974
📅 2026年02月06日
💡 この論文は、不確実な環境下での計画を効率化する「Active Epistemic Control (AEC)」という新しい手法を提案しています。AECは、環境への問い合わせとモデル予測を組み合わせ、確実な情報に基づいて行動を決定することで、計画の実行可能性を保証します。実験結果から、AECは既存のLLMベースのエージェントよりも少ない再計画回数で高い成功率を達成し、効率的な計画能力を示しています。

【5】Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.03975
📅 2026年02月06日
💡 この論文は、大規模言語モデル（LLM）の推論における検証コストを最適化する新しい手法を提案しています。具体的には、中間状態の検証に計算リソースを効率的に割り当てることで、冗長な検証を削減し、推論精度を向上させます。提案手法は、状態レベルの選択的検証フレームワークを採用し、MATHベンチマークにおいて、既存手法よりも少ない検証回数で高い精度を達成しました。この研究は

【6】When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.04003
📅 2026年02月06日
💡 この論文は、AIが生成する説明を操作して、人間のAIへの信頼を誤誘導する「敵対的説明攻撃（AEA）」を紹介しています。AEAは、AIの誤った出力を正当化するような説明を生成し、人間の信頼を維持することで機能します。実験の結果、AEAは特に専門的なコミュニケーションスタイルを用いることで、難しいタスクやAIへの信頼度が高い人々に影響を与え、AIの誤った判断を信じ込ませる可能性

【7】Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.04089
📅 2026年02月06日
💡 この論文は、大規模言語モデル（LLM）が、対話を通じて情報を収集し、時間経過とともに学習するオンライン環境での能力を向上させるための新しい手法「ORBIT」を紹介しています。ORBITは、メタ強化学習を用いてLLMを訓練し、未知の環境でもGPT-5.2に匹敵する性能を発揮することを示しました。この研究は、LLMの学習能力を向上させ、推論時に学習するエージェントの開発に

【8】Interfaze: The Future of AI is built on Task-Specific Small Models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.04101
📅 2026年02月06日
💡 Interfazeは、大規模言語モデル（LLM）に依存せず、タスクに特化した小型モデルとツールを組み合わせたAIシステムです。このアプローチにより、複雑なPDF処理やマルチモーダルタスクにおいて高い精度を達成し、LLMの負荷を軽減します。Interfazeは、計算コストを削減しつつ、多様なタスクに対応できるAIの新たな可能性を示唆しており、今後のAI開発に影響を与える可能性があります。


【9】OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.04144
📅 2026年02月06日
💡 この論文は、マルチモーダルシステムにおけるデータ欠落問題を解決するために、新しいフレームワーク「OMG-Agent」を提案しています。OMG-Agentは、人間の思考プロセスを模倣した「計画-実行」のワークフローを採用し、意味的計画、証拠検索、実行の3つの段階を経て、欠落した情報を生成します。これにより、従来のモデルが抱える問題点を克服し、特にデータ欠落率が高い状況下でも高い精度を維持し、

【10】Steering LLMs via Scalable Interactive Oversight (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2602.04210
📅 2026年02月06日
💡 この論文は、大規模言語モデル（LLM）が複雑なタスクを自動化する中で生じる、人間の監督の難しさに焦点を当てています。提案されている「Scalable Interactive Oversight」フレームワークは、タスクを小さな決定に分解し、人間が各段階でフィードバックを提供することで、LLMを効果的に制御します。この手法は、ウェブ開発タスクで非専門家が専門家レベルの成果物を生成するのに役立ち、

---
合計 128 件のAI関連ニュースが見つかりました。