🤖 AI最新ニュースダイジェスト 🤖
2026年01月28日 13:08

【1】LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.18846
📅 2026年01月28日
💡 この論文は、大規模言語モデル（LLM）を用いて、連続最適化問題のベンチマークテストを改善する方法を提案しています。LLMを使い、問題の構造的特性を自然言語で指定し、進化的なループで問題コードを生成します。これにより、既存のテストスイートでは不足していた多様な構造を持つ最適化問題を生成し、アルゴリズム選択などのタスクに役立つ、解釈可能で再現性のあるベンチマークライブラリ

【2】RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.18924
📅 2026年01月28日
💡 この論文は、大規模言語モデル（LLM）が複雑な指示に従う能力を評価するために、新しいベンチマーク「RIFT」を提案しています。RIFTは、指示の順序を入れ替えることで、LLMが指示の構造にどの程度依存しているかを検証します。実験の結果、LLMは指示の順序が入れ替わるとパフォーマンスが大幅に低下し、指示を逐次的なパターンとして捉えていることが示されました。この結果

【3】Neural Theorem Proving for Verification Conditions: A Real-World Benchmark (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.18944
📅 2026年01月28日
💡 この論文は、プログラム検証における重要なボトルネックである検証条件（VC）の自動証明に焦点を当てています。研究者たちは、実世界のプログラム検証で既存の自動定理証明器（ATP）が苦戦する難しいVCを解決するため、ニューラル定理証明（NTP）をVC証明に適用する初の現実的なベンチマーク「NTP4VC」を開発しました。このベンチマークは、Linuxカーネルなどの実世界のプロジェクトから生成された、

【4】More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19082
📅 2026年01月28日
💡 この論文は、大規模言語モデル（LLM）が自律エージェントとして相互作用する際に、報酬の大きさと言語的文脈がどのように戦略に影響を与えるかを調査しています。研究では、報酬の大きさに応じて戦略が変化し、言語によって異なる行動パターンが見られることが明らかになりました。この結果は、LLMの戦略的行動を理解し、AIガバナンスやマルチエージェントシステムの設計に役立つ可能性を示唆しています。

【5】Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19122
📅 2026年01月28日
💡 この論文は、大規模言語モデル (LLM) の関数呼び出し能力を強化するための新しい手法を提案しています。強化学習を用いて、LLMの弱点を突くような敵対的なクエリを生成し、モデルの堅牢性を高めます。従来のデータセットに依存する手法とは異なり、このアプローチは、LLMが外部ツールとより効果的に連携するための、より汎用的で堅牢なモデルの開発を促進します。


【6】TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19151
📅 2026年01月28日
💡 この論文は、大規模言語モデル（LLM）と時系列分析を組み合わせた新しいフレームワーク「TS-Debate」を提案しています。TS-Debateは、テキスト、視覚パターン、数値信号に特化したエージェントが協調して議論することで、時系列データのゼロショット推論を可能にします。このフレームワークは、数値の正確性を向上させ、異なるモダリティ間の干渉を軽減し、タスク固有の微調整なしに

【7】Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19170
📅 2026年01月28日
💡 この論文は、自然言語から手続き型グラフを自動的に抽出する新しいマルチエージェントフレームワーク「\model{}」を提案しています。このフレームワークは、構造的および論理的な洗練に特化した複数のエージェントを使用し、グラフの構築、構造上の欠陥の診断、論理的な整合性の確保を反復的に行います。自然言語によるフィードバックを重視することで、解釈可能で制御可能な洗練を実現し、既存

【8】CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19193
📅 2026年01月28日
💡 この論文は、マルチモーダルな表理解を向上させるための新しいフレームワーク「CoReTab」を紹介しています。CoReTabは、実行可能なPythonコードと多段階の推論を組み合わせることで、解釈可能で検証可能な注釈を生成します。これにより、MMTabベンチマークにおいて、既存のモデルと比較して大幅な性能向上を達成し、特に多段階推論能力を強化しました。CoReTabは、マルチモーダルな表理解

【9】MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19204
📅 2026年01月28日
💡 この論文では、複雑な視覚推論タスクを解決するために、解釈可能性と効率性を向上させた新しいマルチエージェントシステム「MATA」を紹介しています。MATAは、階層的な有限状態オートマトンとして設計されており、学習可能なハイパーエージェントがトップレベルの遷移を制御します。各エージェントは、ルールベースのサブオートマトンを実行し、共有メモリを介して相互作用することで、透明性の高い実行履歴を

【10】Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2601.19245
📅 2026年01月28日
💡 この論文は、大規模言語モデル（LLM）におけるハルシネーション（事実誤認）を検出するための新しい手法「SpikeScore」を提案しています。既存の手法がドメイン間の一般化に弱いという課題に対し、SpikeScoreはマルチターン対話における不確実性の変動に着目し、異なるドメインでも高い精度でハルシネーションを検出することを目指しています。実験結果は、SpikeScoreが様々なLLMとベン

---
合計 136 件のAI関連ニュースが見つかりました。