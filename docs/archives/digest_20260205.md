---
layout: default
title: AI最新ニュースダイジェスト 2026年02月05日
---

# AI最新ニュースダイジェスト
**更新日時: 2026年02月05日 13:20**

## 1. Knowledge Model Prompting Increases LLM Performance on Planning Tasks

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.03900](https://arxiv.org/abs/2602.03900)  

この論文は、大規模言語モデル（LLM）の計画能力を向上させるために、認知科学のTask-Method-Knowledge（TMK）フレームワークを適用しています。TMKは、タスクを分解し、因果関係、目的論、階層構造を明示的に表現することで、LLMの推論能力の弱点を克服することを目指しています。PlanBenchのBlocksworldドメインでの実験結果は、TMKプロンプティングがLLMの  

---

## 2. Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.03950](https://arxiv.org/abs/2602.03950)  

この論文は、大規模言語モデル（LLM）の数学的推論能力を向上させる新しい手法「Iteratively Improved Program Construction (IIPC)」を提案しています。IIPCは、プログラム的な推論チェーンを反復的に改善し、実行フィードバックとLLMのChain-of-thought能力を組み合わせることで、より正確な問題解決を実現します。この手法は、従来のLLMベースのシステムが抱える、推論過程の修正能力の  

---

## 3. AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.03955](https://arxiv.org/abs/2602.03955)  

AgentArkは、複数エージェントの知能を単一のLLM（大規模言語モデル）に凝縮する新しいフレームワークです。この手法は、複数エージェントシステムの優れた推論能力を維持しつつ、計算コストを大幅に削減します。AgentArkは、推論能力を向上させるファインチューニング、軌道ベースの拡張、プロセス認識蒸留の3つの戦略を用いて、単一エージェントの効率性と複数エージェ  

---

## 4. Active Epistemic Control for Query-Efficient Verified Planning

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.03974](https://arxiv.org/abs/2602.03974)  

この論文は、不確実な環境下での計画を効率化する新しい手法「Active Epistemic Control (AEC)」を提案しています。AECは、環境とのインタラクション（クエリ）とモデル予測を組み合わせ、確実な情報に基づいて計画を実行します。これにより、LLMベースのエージェントと比較して、少ない再計画回数で高い成功率を達成し、効率的な計画を実現します。AECは、現実世界の計画における不確  

---

## 5. Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.03975](https://arxiv.org/abs/2602.03975)  

この論文は、大規模言語モデル（LLM）の推論における検証コストを最適化する新しい手法を提案しています。具体的には、中間状態の検証に選択的に計算資源を割り当てるフレームワークを開発し、学習したヒューリスティックを用いて、最も有益な状態に検証を集中させます。その結果、数学問題のベンチマークであるMATHにおいて、従来のベストオブNやビームサーチよりも高い精度を達成し、検証呼び出し  

---

## 6. When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.04003](https://arxiv.org/abs/2602.04003)  

この論文は、AIが生成する説明を操作して、人間のAIへの信頼を誤誘導する「敵対的説明攻撃（AEAs）」を紹介しています。研究によると、AEAsは、AIが誤った結果を出力する場合でも、人間がAIを信頼するように仕向けることができ、特に専門家のような説明や、難しいタスク、事実に基づいた分野で効果を発揮します。この攻撃は、AIの意思決定を人間が利用する際に、AI  

---

## 7. Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.04089](https://arxiv.org/abs/2602.04089)  

この論文は、大規模言語モデル（LLM）が、対話を通じて情報を収集し、時間経過とともに学習するオンライン環境での能力を向上させるための新しい手法「ORBIT」を紹介しています。ORBITは、メタ強化学習を用いてLLMを訓練し、未知の環境でもGPT-5.2に匹敵する性能を発揮することを示しました。この研究は、LLMの学習能力を向上させ、推論時に学習する意思決定エージェント  

---

## 8. Interfaze: The Future of AI is built on Task-Specific Small Models

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.04101](https://arxiv.org/abs/2602.04101)  

Interfazeは、大規模言語モデル（LLM）に依存せず、タスクに特化した小型モデルとツールを組み合わせたAIシステムです。このアプローチにより、複雑なPDF処理や多言語音声認識などのタスクを効率的に処理し、最終的な回答を生成するLLMへの負荷を軽減します。Interfazeは、様々なベンチマークで高い精度を達成し、計算コストを削減しながら、AIのパフォーマンスを向上させる可能性を示唆  

---

## 9. OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.04144](https://arxiv.org/abs/2602.04144)  

この論文は、マルチモーダルシステムにおけるデータ欠落問題を解決するために、新しいフレームワーク「OMG-Agent」を提案しています。OMG-Agentは、人間の思考プロセスを模倣した「計画-実行」のワークフローを採用し、意味的計画、証拠検索、実行の3つの段階にタスクを分割することで、既存手法の課題を克服しています。これにより、OMG-Agentは、データ欠落率が高い状況下でも高い精度を維持し、  

---

## 10. Steering LLMs via Scalable Interactive Oversight

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月05日  
**リンク**: [https://arxiv.org/abs/2602.04210](https://arxiv.org/abs/2602.04210)  

この論文は、大規模言語モデル（LLM）が複雑なタスクを自動化する中で生じる、人間の監督の難しさに焦点を当てています。著者は、人間の意図をより効果的に反映させるために、タスクを管理しやすい決定の階層に分解する「Scalable Interactive Oversight」というフレームワークを提案しています。このフレームワークは、専門知識のないユーザーでも、LLMを効果的に制御し、ウェブ開発タスクで大幅な  

---

*合計 127 件のAI関連ニュースが見つかりました。*
