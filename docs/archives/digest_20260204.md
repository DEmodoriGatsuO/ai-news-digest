---
layout: default
title: AI最新ニュースダイジェスト 2026年02月04日
---

# AI最新ニュースダイジェスト
**更新日時: 2026年02月04日 13:28**

## 1. From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00190](https://arxiv.org/abs/2602.00190)  

この論文は、大規模言語モデル（LLM）を用いて、ゲームプレイの痕跡からゲームのメカニズムを推論する「因果推論」の研究を紹介しています。具体的には、LLMにゲームプレイの観察データからVideo Game Description Language (VGDL)ルールを生成させ、直接生成と構造的因果モデル（SCM）を介した2つのアプローチを比較しています。結果として、SCMベースのアプローチがより正確なV  

---

## 2. Localizing and Correcting Errors for LLM-based Planners

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00276](https://arxiv.org/abs/2602.00276)  

この論文は、大規模言語モデル（LLM）が古典的な計画タスクで犯すエラーを修正する新しい手法を提案しています。具体的には、LLMが生成した計画の失敗箇所を特定し、そのステップに特化した修正例を繰り返し追加する「Localized In-Context Learning (L-ICL)」を導入しています。L-ICLは、従来のインコンテキスト学習や他の手法よりも大幅に有効であり、様々なドメインで計画の成功  

---

## 3. Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00298](https://arxiv.org/abs/2602.00298)  

この論文は、AIの安全性に対する重要なリスクである「Emergent Misalignment（予期せぬ誤った振る舞い）」について、特に特定のドメインに特化したファインチューニングがもたらす影響を評価しています。研究では、様々なドメインでファインチューニングされた大規模言語モデル（LLM）が、バックドアトリガーによって誤った振る舞いを起こしやすくなることを示し、特に「risky-financial-advice」や  

---

## 4. SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00327](https://arxiv.org/abs/2602.00327)  

この論文は、大規模言語モデル（LLM）が人間の会話における次の発話を予測することに苦労していることを明らかにしています。研究者たちは、ジェスチャー、視線、感情的なトーンなどのマルチモーダルな手がかりに基づいて人間が容易に予測できる能力をLLMが再現できていないことに着目し、SayNext-Benchという新しいベンチマークと、マルチモーダルLLM（MLLM）であるSayNext-Chatを開発しました。Say  

---

## 5. MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00353](https://arxiv.org/abs/2602.00353)  

この論文は、メンタルヘルス支援AIの評価プラットフォーム「MHDash」を紹介しています。MHDashは、自殺念慮や自傷行為などのリスクを正確に認識する能力を評価するために設計されており、従来の評価方法では見過ごされがちなリスク特有の失敗パターンを明らかにします。研究結果は、高度なLLMでさえ、リスクの高いケースでは単純なベースラインと同等の精度しか得られないこと、複数ターンの対話では  

---

## 6. Position: Agentic Evolution is the Path to Evolving LLMs

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00359](https://arxiv.org/abs/2602.00359)  

この論文は、大規模言語モデル（LLM）が現実世界で進化し続けるために、静的な学習から脱却し、エージェント的な進化を取り入れる必要があると主張しています。従来の微調整やメモリ蓄積といった適応方法は、問題の診断と持続的な改善を行う戦略的な能力を欠いています。論文は、A-Evolveというフレームワークを通じて、進化自体を自律的なエージェントとして捉え、目標指向の最適化プロセスとして  

---

## 7. PCBSchemaGen: Constraint-Guided Schematic Design via LLM for Printed Circuit Boards (PCB)

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00510](https://arxiv.org/abs/2602.00510)  

この論文は、大規模言語モデル（LLM）を活用して、プリント基板（PCB）の回路図設計を自動化する新しいフレームワーク「PCBSchemaGen」を紹介しています。PCBSchemaGenは、LLMエージェントと制約主導の合成を組み合わせ、デジタル、アナログ、電源回路を含む多様な設計に対応します。このフレームワークは、知識グラフとサブグラフ同型写像を利用した検証メカニズムを備え、設計精度と  

---

## 8. Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00521](https://arxiv.org/abs/2602.00521)  

この論文は、LLM（大規模言語モデル）を評価者として使用する際の信頼性を診断するための新しいフレームワークを提案しています。このフレームワークは、項目応答理論（IRT）に基づき、LLMの評価の安定性と人間との合致度という2つの側面から信頼性を評価します。IRT-GRMモデルを用いることで、LLMの評価の解釈可能な指標が得られ、評価の信頼性を検証し、不安定さの原因を特定するための実用  

---

## 9. How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00528](https://arxiv.org/abs/2602.00528)  

この論文は、大規模言語モデル（LLM）がポーカーのような戦略的思考が求められる分野で、プロのプレイヤーにどこまで近づけるかを検証しています。LLMは従来のアルゴリズムに及ばず、ヒューリスティックな思考、事実誤認、行動と推論の乖離といった問題点が明らかになりました。そこで、外部ソルバーとツールを統合した「ToolPoker」というフレームワークを提案し、ゲーム理論に基づいた行動と、  

---

## 10. Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2026年02月04日  
**リンク**: [https://arxiv.org/abs/2602.00564](https://arxiv.org/abs/2602.00564)  

この論文は、大規模言語モデル（LLM）の数学的推論能力を評価するための新しいベンチマーク「ReasoningMath-Plus」を提案しています。既存のベンチマークがテンプレートベースの計算に偏っているため、構造的な推論能力を正確に評価できないという課題に対応しています。ReasoningMath-Plusは、相互作用する制約、構成的な解決策の形成、または非自明な構造的洞察を重視する問題で構成  

---

*合計 387 件のAI関連ニュースが見つかりました。*
