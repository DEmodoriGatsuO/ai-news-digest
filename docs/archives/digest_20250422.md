---
layout: default
title: AI最新ニュースダイジェスト 2025年04月22日
---

# AI最新ニュースダイジェスト
**更新日時: 2025年04月22日 11:46**

## 1. Going Whole Hog: A Philosophical Defense of AI Cognition

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.13988](https://arxiv.org/abs/2504.13988)  

この論文は、ChatGPTのような大規模言語モデル（LLM）が、理解、信念、欲求、知識、意図といった完全な認知能力を持つという「Whole Hog Thesis」を擁護しています。著者は、LLMの行動を観察し、認知状態間の関係性を仮定することで、LLMが認知エージェントであると主張しています。LLMの誤りや、意味的基盤、身体性、正当化といった認知の必要条件に関する異  

---

## 2. Multi-Stage Retrieval for Operational Technology Cybersecurity Compliance Using Large Language Models: A Railway Casestudy

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14044](https://arxiv.org/abs/2504.14044)  

この論文は、大規模言語モデル（LLM）と多段階検索を活用して、鉄道などの重要インフラにおけるOT（Operational Technology）サイバーセキュリティコンプライアンスを強化する新しいシステムを提案しています。具体的には、IEC 62443やIEC 63452などの規格に対するコンプライアンス検証を改善するため、OpenAI-gpt-4oやClaude-3.5-haikuなどのLLMを用いて、既存のアーキ  

---

## 3. Metacognition and Uncertainty Communication in Humans and Large Language Models

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14045](https://arxiv.org/abs/2504.14045)  

この論文は、人間と大規模言語モデル（LLM）におけるメタ認知能力、つまり自己の知識やパフォーマンスを監視・評価する能力を比較検討しています。研究者たちは、LLMが人間と似たようなメタ認知能力を示す場合がある一方で、大きな違いも存在することを示唆しています。この違いを理解することは、人間とAIの協調を深め、より信頼できるAIシステムの開発に不可欠であり、LLMのメタ認知能力を向上させる  

---

## 4. Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14047](https://arxiv.org/abs/2504.14047)  

この論文は、大規模言語モデル（LLM）の推論能力を向上させるための、推論時間計算（ITC）手法の効率性を検証しています。特に、検証器を必要としない手法に焦点を当て、様々なモデルにおけるITCの効果を分析しています。その結果、推論モデルは、非推論モデルよりも高い性能を示し、多数決投票が最も効果的なITC戦略であることが判明しました。また、応答の長さや言語的特徴が応答  

---

## 5. Linking forward-pass dynamics in Transformers and real-time human processing

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14107](https://arxiv.org/abs/2504.14107)  

この論文は、Transformerモデルの内部処理（層ごとの計算）と人間のリアルタイム処理の関連性を探求しています。研究では、Transformerモデルの層ごとの計算過程が、人間の認知プロセスを予測できることを示し、モデルの出力だけでなく、内部のダイナミクスも人間の認知を理解する上で重要であることを示唆しています。この結果は、AIモデルが人間の認知を研究するための新たなツールとなり、人間の思考プロセスを模倣する可能性を示唆  

---

## 6. CODECRASH: Stress Testing LLM Reasoning under Structural and Semantic Perturbations

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14119](https://arxiv.org/abs/2504.14119)  

この論文は、大規模言語モデル（LLM）のコード理解と推論能力の堅牢性を評価する新しいベンチマーク「CodeCrash」を提案しています。CodeCrashは、コードの構造的およびテキスト的な撹乱に対するLLMの耐性をテストし、その脆弱性を明らかにしました。研究結果は、LLMが構造的なノイズに弱く、自然言語のヒントに依存していることを示し、コード実行と理解における重要な課題を浮  

---

## 7. Large Language Model Enhanced Particle Swarm Optimization for Hyperparameter Tuning for Deep Learning Models

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14126](https://arxiv.org/abs/2504.14126)  

この論文は、大規模言語モデル（LLM）を粒子群最適化（PSO）に統合し、深層学習モデルのハイパーパラメータ調整を効率化する新しい手法を提案しています。LLM（ChatGPT-3.5とLlama3）を活用してPSOの探索を加速し、モデル評価回数を削減することで、従来のPSOよりも20%から60%の計算コスト削減と、高い収束率を実現しました。実験では、時系列回  

---

## 8. TALES: Text Adventure Learning Environment Suite

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14128](https://arxiv.org/abs/2504.14128)  

この論文は、大規模言語モデル (LLM) の推論能力を評価するための、テキストアドベンチャーゲームのスイート「TALES」を紹介しています。TALESは、多様な推論能力を試すために設計された、合成および人間が作成したゲームで構成されています。実験結果によると、LLMは合成ゲームでは良い成績を収めるものの、人間が楽しむために設計されたゲームでは苦戦しており、LLMの推論能力の限界を示  

---

## 9. Direct Advantage Regression: Aligning LLMs with Online AI Reward

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14177](https://arxiv.org/abs/2504.14177)  

この論文は、大規模言語モデル（LLM）を調整するための新しい手法「Direct Advantage Regression (DAR)」を提案しています。DARは、人間のフィードバックの代わりにAIの報酬を利用し、重み付けされた教師ありファインチューニングを通じてポリシーを最適化します。このRLフリーのアプローチは、実装を簡素化し、学習効率を向上させながら、従来のオンライン強化学習手法と同等の性能を発揮します。実験結果は、DARがAI  

---

## 10. AI Idea Bench 2025: AI Research Idea Generation Benchmark

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年04月22日  
**リンク**: [https://arxiv.org/abs/2504.14191](https://arxiv.org/abs/2504.14191)  

この論文は、AI研究におけるアイデア生成能力を評価するための新しいベンチマーク「AI Idea Bench 2025」を紹介しています。既存の評価方法が抱える問題点を克服し、LLMが生成したアイデアの質を、元の論文との整合性と一般知識に基づいて定量的に評価します。3,495件のAI論文と関連研究を含む包括的なデータセットを使用し、科学的発見の自動化を促進する可能性を秘めています。  

---

*合計 150 件のAI関連ニュースが見つかりました。*
