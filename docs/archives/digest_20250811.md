---
layout: default
title: AI最新ニュースダイジェスト 2025年08月11日
---

# AI最新ニュースダイジェスト
**更新日時: 2025年08月11日 12:59**

## 1. InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.05731](https://arxiv.org/abs/2508.05731)  

この論文は、GUI操作を視覚情報だけで行う自律エージェントの性能向上を目指し、自然言語命令の理解を深めるための新しい手法「Adaptive Exploration Policy Optimization (AEPO)」を提案しています。AEPOは、効率的な探索を促すために、複数回答生成戦略と、効率性に基づいた報酬関数「Adaptive Exploration Reward (AER)」を採用しています。その結果、InfiGUI-G1モデルは、GUIグラウンディングのベン  

---

## 2. A Framework for Inherently Safer AGI through Language-Mediated Active Inference

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.05766](https://arxiv.org/abs/2508.05766)  

この論文は、大規模言語モデル（LLM）と能動的推論を組み合わせることで、安全な汎用人工知能（AGI）を開発するための新しいフレームワークを提案しています。従来の事後的な解釈可能性や報酬設計に依存するAI安全アプローチの限界を克服するため、透明性の高い信念表現と階層的な価値観の整合性を中核に据えたアーキテクチャを構築しています。自然言語を介して信念を  

---

## 3. Safety of Embodied Navigation: A Survey

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.05855](https://arxiv.org/abs/2508.05855)  

この論文は、大規模言語モデルの進歩に伴い注目を集める「具現化されたナビゲーション」の安全性に焦点を当てた調査です。具現化されたナビゲーションは、現実世界での応用が増えるにつれて安全性が重要になり、攻撃手法、防御メカニズム、評価方法など、多角的な視点から安全性を分析しています。未解決の問題や今後の研究方向性も提示し、より安全で信頼性の高い具現化  

---

## 4. Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.05996](https://arxiv.org/abs/2508.05996)  

この論文は、医療における意思決定を支援するために、オープンソースの視覚言語モデル（VLM）を連携させる新しいフレームワーク「MedOrch」を提案しています。MedOrchは、大規模言語モデル（LLM）を仲介役として活用し、複数のVLM専門家が互いの出力を交換し、自己反省することで協調的な意思決定を促進します。このアプローチにより、個々のモデルの能力を超えるパフォーマンスを達成し、  

---

## 5. Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.06042](https://arxiv.org/abs/2508.06042)  

この論文は、大規模言語モデル（LLM）が苦手とする、リアルタイム戦略ゲームのような動的で長期的なタスクを解決するために、階層型マルチエージェントフレームワーク「HIMA」を提案しています。HIMAは、専門的な模倣学習エージェントを戦略プランナー（SP）が統括し、環境に適応した計画を立てることで、戦略的明瞭さ、適応性、計算効率を向上させています。研究  

---

## 6. LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.06060](https://arxiv.org/abs/2508.06060)  

この論文は、大規模言語モデル（LLM）が資源配分タスクをどのように処理できるかを調査しています。参加型予算編成（PB）を、LLMの資源配分能力を評価するための実践的な設定と適応型ベンチマークとして利用しています。LLMは、予算などの制約の下でプロジェクトを選択し、自然言語の投票入力から構造化された選好を推測する能力をテストされます。研究結果は、プロンプト設計  

---

## 7. PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.06110](https://arxiv.org/abs/2508.06110)  

この論文は、LLM（大規模言語モデル）エージェントを用いた新しいテーブル推論フレームワーク「PanelTR」を紹介しています。PanelTRは、複数のエージェントが科学的な議論を通じてテーブルに関する質問に答えるもので、データ拡張や事前学習なしで、従来のLLMよりも優れた性能を示しています。このフレームワークは、科学的な方法論を模倣することで、テーブル推論だけでなく、他の複雑なタスクにも応用できる可能性を示唆しており、AI分野  

---

## 8. SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.06111](https://arxiv.org/abs/2508.06111)  

この論文では、大規模言語モデル（LLM）の能力を評価するための新しいフレームワーク「SKATE」を紹介しています。SKATEは、LLMが互いに検証可能な課題を作成し、解決することで競争するゲームのような評価方法を採用しています。このアプローチにより、人間の専門知識を必要とせず、スケーラブルで客観的な評価が可能になります。実験の結果、SKATEは、より弱いモデルでもより強いモデルを区別でき、LLMが自己  

---

## 9. Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.06145](https://arxiv.org/abs/2508.06145)  

この研究は、大規模言語モデル（LLM）の医療分野への応用、特に医薬品禁忌に関する課題を解決するため、検索拡張生成（RAG）パイプラインを実装しました。OpenAIのGPT-4o-miniを基盤モデルとし、Langchainを活用したハイブリッド検索システムを構築し、公開データベースの医薬品利用レビュー（DUR）データから禁忌情報を取得しました。その結果、RAGパイプラインの導入により、  

---

## 10. Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年08月11日  
**リンク**: [https://arxiv.org/abs/2508.06225](https://arxiv.org/abs/2508.06225)  

この論文は、大規模言語モデル（LLM）を「裁判官」として使用する際の信頼性向上に焦点を当てています。LLMは自信過剰になりやすく、実際の正解率よりも高い自信を示すことが問題点として指摘されています。論文では、この問題を定量化する新しい指標「TH-Score」を導入し、LLMをより信頼性の高い評価者へと変えるアンサンブルフレームワーク「LLM-as-a-Fuser」  

---

*合計 96 件のAI関連ニュースが見つかりました。*
