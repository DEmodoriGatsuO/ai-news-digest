---
layout: default
title: AI最新ニュースダイジェスト 2025年06月02日
---

# AI最新ニュースダイジェスト
**更新日時: 2025年06月02日 12:58**

## 1. Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.23881](https://arxiv.org/abs/2505.23881)  

この論文は、推論能力を持つ大規模言語モデル（LLM）を用いて、組み合わせデザイン問題の未解決事例を解くための探索ヒューリスティックを生成する新しい手法「CPro1」を提案しています。CPro1は、LLMに問題定義と検証器を与え、戦略の選択と実装をガイドし、自動的なハイパーパラメータ調整とフィードバックを提供します。その結果、CPro1は、長年未解決だった7つの  

---

## 2. OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.23885](https://arxiv.org/abs/2505.23885)  

この論文は、現実世界のタスク自動化における大規模言語モデル（LLM）ベースのマルチエージェントシステムの課題を解決する「Workforce」という新しいフレームワークを紹介しています。Workforceは、戦略的計画と専門的な実行を分離するモジュール構造を採用し、ドメイン間の転送を容易にしています。特に、OWL（Optimized Workforce Learning）と呼ばれる手法を用いて、ドメインに依存しないプランナーを最適化し、様々な現実世界のタスク  

---

## 3. Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.23946](https://arxiv.org/abs/2505.23946)  

この論文は、コード生成LLMのチームが互いの成功と失敗から学び、パフォーマンスを向上させるための新しいフレームワークを提案しています。異なるLLMが異なるコード最適化スキルを持つことに着目し、各エージェントが「レッスン」を通じて知識を共有することで、より大きなLLMよりも優れた結果を達成できることを実証しています。このアプローチは、AI開発における協調学習の可能性を示唆し、特にリソースが限られた状況下  

---

## 4. InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.23950](https://arxiv.org/abs/2505.23950)  

この論文は、マルチモーダル大規模言語モデル（MLLM）の重要な課題である、複数ターンにわたるマルチモーダルなインタラクション能力の欠如に対処しています。研究者らは、人間のフィードバックに基づいた初のマルチターンマルチモーダルインタラクション用データセット「InterMT」を構築し、MLLMの評価と改善に貢献しています。InterMTは、人間の好みに関する詳細な情報を収集し、MLLMが複雑な対話形式  

---

## 5. MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.23982](https://arxiv.org/abs/2505.23982)  

この論文は、大学院レベルの材料科学におけるLLMの能力を評価するための新しいベンチマーク「MSQA」を紹介しています。MSQAは、詳細な説明と真偽判定の2つの形式で、1,757問の質問を通じて、LLMの専門知識と複雑な推論能力を試します。実験の結果、APIベースのLLMは高い精度を示しましたが、オープンソースLLMや専門分野に特化したLLMは性能が  

---

## 6. Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.23990](https://arxiv.org/abs/2505.23990)  

この論文は、動的な状況下での人間の認知負荷を軽減するために設計された、マルチモーダル検索拡張生成システム「Multi-RAG」を紹介しています。Multi-RAGは、ビデオ、オーディオ、テキストなどの複数の情報源を統合し、状況理解を向上させることを目指しています。MMBench-Videoデータセットでの評価では、既存のビデオLLMやLVLMよりも優れた性能を示し、少ないリソースで高い効率性を実現しました。この研究  

---

## 7. GenIC: An LLM-Based Framework for Instance Completion in Knowledge Graphs

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.24036](https://arxiv.org/abs/2505.24036)  

この論文は、知識グラフのインスタンス補完問題を解決するために、大規模言語モデル（LLM）を活用した新しいフレームワーク「GenIC」を提案しています。GenICは、エンティティの説明とタイプをLLMで解析し、関係とテールを予測する2段階のアプローチを採用しています。実験結果は、GenICが既存のベースラインよりも優れた性能を示しており、知識グラフの構築と利用における効率化に貢献する可能性があります。
  

---

## 8. Leave it to the Specialist: Repair Sparse LLMs with Sparse Fine-Tuning via Sparsity Evolution

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.24037](https://arxiv.org/abs/2505.24037)  

この論文は、大規模言語モデル（LLM）の計算コストを削減するために、スパース（疎）LLM向けに設計された新しいファインチューニング手法「Sparsity Evolution Fine-Tuning (SEFT)」を提案しています。SEFTは、ファインチューニング中にスパース構造を動的に進化させ、タスク固有の適応を可能にすることで、既存の手法よりも優れたパフォーマンスと効率性を実現します。この手法は、LLMの  

---

## 9. SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.24181](https://arxiv.org/abs/2505.24181)  

この論文は、大規模言語モデル (LLM) の推論能力を向上させる新しい手法「Flow Chain of Thought (Flow CoT)」を紹介しています。Flow CoTは、反復的な推論を段階的な認知状態の軌跡としてモデル化し、SCOUTと呼ばれる軽量なファインチューニングフレームワークを通じて実現します。SCOUTは、教師あり学習とクロスアテンションモジュールを活用し、事前のトレーニングなしで、推論の精度と説明  

---

## 10. Learning API Functionality from Demonstrations for Tool-based Agents

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年06月02日  
**リンク**: [https://arxiv.org/abs/2505.24197](https://arxiv.org/abs/2505.24197)  

この論文は、APIの機能をデモンストレーションから学習する新しいパラダイムを提案しています。特に、APIドキュメントが不足している場合に有効で、専門家や自己探索からのデモンストレーションを利用します。実験の結果、LLM（大規模言語モデル）を用いたAPIベースのエージェントのタスク成功率は、明示的な関数呼び出しと自然言語での評価を提供することで向上することが示されました。この研究は、ドキュメントに依存しない、自己  

---

*合計 209 件のAI関連ニュースが見つかりました。*
