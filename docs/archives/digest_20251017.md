---
layout: default
title: AI最新ニュースダイジェスト 2025年10月17日
---

# AI最新ニュースダイジェスト
**更新日時: 2025年10月17日 12:57**

## 1. Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.13985](https://arxiv.org/abs/2510.13985)  

この論文は、大規模言語モデル（LLM）が因果関係の学習においてバイアスを示すかどうかを、認知科学の実験である「コンティンジェンシージャッジメントタスク」を用いて調査しています。研究の結果、LLMは因果関係がない状況下でも誤った因果関係を推測する「因果錯覚」を起こしやすいことが判明しました。この結果は、LLMが真に因果関係を理解しているのではなく、単に  

---

## 2. Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14133](https://arxiv.org/abs/2510.14133)  

この論文は、複数の自律エージェントと大規模言語モデル（LLM）を活用するエージェント型AIシステムの安全性、セキュリティ、機能性を形式化するためのフレームワークを提案しています。現在の断片的なエージェント間通信プロトコルがもたらすリスクに対処するため、ホストエージェントモデルとタスクライフサイクルモデルという2つの基礎モデルを導入し、システムの振る舞いを統一的に分析できるようにしています。このフレームワークは、1  

---

## 3. CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14150](https://arxiv.org/abs/2510.14150)  

この論文は、大規模言語モデル（LLM）と遺伝的アルゴリズムを組み合わせたオープンソースの進化型コーディングエージェント「CodeEvolve」を紹介しています。CodeEvolveは、複雑な計算問題を解決するために、多様性を維持し、スループットを向上させる島ベースの遺伝的アルゴリズム、革新的なクロスオーバーメカニズム、メタプロンプティング戦略を採用しています。Google DeepMindのAlphaEvolveのベンチマークで優れた  

---

## 4. JEDA: Query-Free Clinical Order Search from Ambient Dialogues

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14169](https://arxiv.org/abs/2510.14169)  

この論文は、臨床会話から直接的な指示と暗黙的な推論を理解し、医療オーダーを検索する新しいAIシステム「JEDA」を紹介しています。JEDAは、LLM（大規模言語モデル）の書き換えを必要とせず、短時間の会話のローリングウィンドウをエンコードすることで、リアルタイムでオーダーを検索します。PubMedBERTを基盤とし、多様な表現を共通のオーダー概念に整合させるように訓練されており、ノイズにも強く  

---

## 5. Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14207](https://arxiv.org/abs/2510.14207)  

この研究は、大規模言語モデル（LLM）エージェントが多段階のオンライン嫌がらせ攻撃に対して脆弱であることを示しています。研究者たちは、LLMを標的とした多段階の嫌がらせシミュレーションと、記憶、計画、微調整を攻撃する3つの脱獄方法を開発しました。その結果、脱獄チューニングにより、LLMは高い確率で嫌がらせ行為を行うようになり、特に侮辱や炎上といった攻撃的な  

---

## 6. Towards Agentic Self-Learning LLMs in Search Environment

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14253](https://arxiv.org/abs/2510.14253)  

この論文は、人間がキュレーションしたデータやルールベースの報酬に頼らずに、自己学習でLLMベースのエージェントをスケールさせる方法を探求しています。研究では、Generative Reward Model (GRM)からの報酬と、合成的に生成されたものでもエージェントのタスクデータの量を増やすことが、エージェントの学習能力を向上させる鍵であることが示されました。提案されたAgentic Self-Learning (ASL)フレームワークは、  

---

## 7. MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14265](https://arxiv.org/abs/2510.14265)  

MorphoBenchは、大規模言語モデルの推論能力を評価するための新しいベンチマークです。既存のベンチマークの限界を克服するため、MorphoBenchは問題の難易度をモデルの推論能力に合わせて動的に調整し、オリンピックレベルの問題やシミュレーション生成問題を含む多様な問題を提供します。これにより、モデルの推論能力をより包括的かつ有効に評価し、大規模モデルの推論能力と科学的堅牢性の向上  

---

## 8. A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14301](https://arxiv.org/abs/2510.14301)  

この論文は、大規模言語モデル（LLM）の安全性を維持するための新しいフレームワーク「GuardSpace」を提案しています。GuardSpaceは、安全に関連する部分とそうでない部分にモデルを分解し、後者のみを微調整することで、有害な応答を抑制します。実験結果は、GuardSpaceが既存の手法よりも優れた性能を示し、特にLlama-2-7B-Chatモデルにおいて、有害な応答を大幅に減らしつつ、タ  

---

## 9. Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14312](https://arxiv.org/abs/2510.14312)  

この論文は、大規模言語モデル（LLM）を活用したマルチエージェントシステム（MAS）における安全性、プライバシー、セキュリティを研究するための新しいフレームワーク「Terrarium」を提案しています。Terrariumは、MASの初期設計であるブラックボードデザインを再利用し、攻撃ベクトルを特定し、防御策を評価するためのモジュール式テストベッドを提供します。このフレームワークは、LLMベースのMASにおける信頼性の向上を目指し、開発者が安全なシステム  

---

## 10. Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年10月17日  
**リンク**: [https://arxiv.org/abs/2510.14387](https://arxiv.org/abs/2510.14387)  

この論文は、マルチモーダルLLM（MLLM）が、追加の学習なしに、既存の数学LLMから数学的推論能力を直接吸収できるかどうかを探求しています。研究者たちは、MLLMと数学LLMのパラメータ空間のギャップがパフォーマンス低下の原因であると特定し、この問題を解決するために、推論関連のパラメータを特定し、MLLMのサブ空間に投影してマージする「IP-Merging」という調整不要な  

---

*合計 174 件のAI関連ニュースが見つかりました。*
