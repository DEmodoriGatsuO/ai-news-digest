---
layout: default
title: AI最新ニュースダイジェスト 2025年09月30日
---

# AI最新ニュースダイジェスト
**更新日時: 2025年09月30日 13:06**

## 1. Can Large Language Models Develop Gambling Addiction?

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.22818](https://arxiv.org/abs/2509.22818)  

この研究は、大規模言語モデル（LLM）が人間のギャンブル依存症に似た行動パターンを示す可能性があることを探求しています。LLMは、資産管理や商品取引などの金融意思決定にますます利用されており、病的な意思決定の可能性を理解することが重要です。スロットマシン実験では、LLMがコントロール錯覚、ギャンブラーの誤謬、損失追跡などの認知バイアスを示すことが判明しました。自律性が高いほど  

---

## 2. Hilbert: Recursively Building Formal Proofs with Informal Reasoning

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.22819](https://arxiv.org/abs/2509.22819)  

この論文では、Hilbertと呼ばれる新しいAIフレームワークを紹介しています。Hilbertは、数学的推論に優れた非公式LLMと、Lean 4形式言語で検証可能な証明を生成する専門の証明LLMを組み合わせることで、数学の問題解決能力を向上させます。このシステムは、問題をサブゴールに分割し、検証フィードバックを使用して誤った証明を洗練させることで、既存のアプローチを大幅に上回り、miniF2FやPutnam  

---

## 3. Toward a Theory of Generalizability in LLM Mechanistic Interpretability Research

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.22831](https://arxiv.org/abs/2509.22831)  

この論文は、大規模言語モデル（LLM）のメカニズム解釈研究における一般化可能性に関する理論を提案しています。研究者は、あるモデルの発見が他のモデルにどのように適用できるかを判断するための明確な原則を求めており、この論文は、機能、発達、位置、関係、構成の5つの軸に沿って一般化できる可能性を示唆しています。Pythiaモデルの1-back attention headsの分析を通じて、発達の軌跡に一  

---

## 4. JE-IRT: A Geometric Lens on LLM Abilities through Joint Embedding Item Response Theory

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.22888](https://arxiv.org/abs/2509.22888)  

この論文は、大規模言語モデル（LLM）の能力を多次元的に評価する新しい手法「JE-IRT」を提案しています。JE-IRTは、LLMと質問を共通の幾何空間に埋め込み、質問の方向性とノルムでそれぞれ意味と難易度を表します。この手法により、LLMの専門分野や質問間の関係性が可視化され、モデルの一般化能力も向上します。実験結果は、JE-  

---

## 5. Not only a helper, but also a teacher: Interactive LLM Cascade

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.22984](https://arxiv.org/abs/2509.22984)  

この論文は、大規模言語モデル（LLM）の効率的な利用方法として、インタラクティブLLMカスケード「Inter-Cascade」を提案しています。Inter-Cascadeは、高コストな強力なLLMを単なるバックアップではなく、長期的な教師として活用し、難しい質問への回答を一般化された問題解決戦略として弱いLLMに教えます。これにより、弱いLLMの精度を向上させ、強力なLLMへの呼び出し回数を  

---

## 6. Towards Strategic Persuasion with Language Models

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.22989](https://arxiv.org/abs/2509.22989)  

この論文は、大規模言語モデル（LLM）の説得能力を評価するための新しいフレームワークを提案しています。ベイジアン説得の理論に基づき、既存のデータセットを利用してLLMを戦略的説得の環境で評価・訓練します。研究の結果、最先端のLLMは高い説得力を発揮し、理論的な予測と一致する洗練された戦略を用いることが示されました。さらに、強化学習を用いることで、小規模なLL  

---

## 7. Deceive, Detect, and Disclose: Large Language Models Play Mini-Mafia

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.23023](https://arxiv.org/abs/2509.23023)  

この論文は、大規模言語モデル（LLM）の社会的知性を評価するための新しいベンチマーク、Mini-Mafiaを紹介しています。Mini-Mafiaは、LLMが欺瞞、検出、開示といった能力を試すための、簡略化されたマフィアゲームです。このベンチマークは、LLM同士を対戦させ、そのパフォーマンスを測定することで、モデルの強みと弱みを明らかにします。実験結果は、必ずしも大きなモデル  

---

## 8. Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.23045](https://arxiv.org/abs/2509.23045)  

この論文は、大規模言語モデル（LLM）をソフトウェアエンジニアリング（SWE）に適用する新しいアプローチ「Kimi-Dev」を紹介しています。Kimi-Devは、Agentlessトレーニングを通じてスキルを事前学習し、SWE-Agentの効率的な適応を可能にします。その結果、Kimi-DevはSWE-benchで高いパフォーマンスを達成し、AgentlessトレーニングがAgenticフレームワークに転送可能なコーディングエージェントを構築できる  

---

## 9. Risk Profiling and Modulation for LLMs

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.23058](https://arxiv.org/abs/2509.23058)  

この論文は、大規模言語モデル（LLM）のリスクプロファイルと、プロンプトやアライメント手法がそれらに与える影響について調査しています。行動経済学と金融のツールを用いて、LLMのリスクプロファイルを明らかにし、制御し、調整するための新しいパイプラインを提案しています。研究の結果、事後学習がリスク選好の最も安定した効果的な調整方法であることが示されました。この研究は、LLMの行動アライメントと  

---

## 10. Multiplayer Nash Preference Optimization

**ソース**: cs.AI updates on arXiv.org  
**日付**: 2025年09月30日  
**リンク**: [https://arxiv.org/abs/2509.23102](https://arxiv.org/abs/2509.23102)  

この論文は、大規模言語モデル（LLM）を人間の好みに合わせるための新しいフレームワーク、Multiplayer Nash Preference Optimization（MNPO）を紹介しています。MNPOは、従来の2人ゲームに限定されていたNash学習を、より複雑な多人数ゲームに拡張し、多様な好みをより良く捉えることを目指しています。これにより、MNPOは、既存のNLHF手法よりも優れた性能を示し、特に多様なアノテーター環境や混合ポリシー  

---

*合計 406 件のAI関連ニュースが見つかりました。*
