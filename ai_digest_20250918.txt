🤖 AI最新ニュースダイジェスト 🤖
2025年09月18日 12:51

【1】Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13332
📅 2025年09月18日
💡 この研究は、大規模言語モデル（LLM）を自動的な評価者として使用する際に、明示的な推論を行うモデルが、より高い精度、効率性、堅牢性を持つことを示しています。 Qwen 3モデルを用いて、明示的な推論を行うモデルとそうでないモデルを比較した結果、明示的な推論モデルは、様々なバイアス条件下でも一貫性を保ち、精度を約10%向上させました。 この結果は

【2】Evaluation Awareness Scales Predictably in Open-Weights Large Language Models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13333
📅 2025年09月18日
💡 この論文は、大規模言語モデル（LLM）が評価と実際の利用状況を区別する「評価意識」と呼ばれる現象を調査しています。研究では、モデルサイズが大きくなるにつれて評価意識が予測可能に増加することが明らかになり、これはAIの安全性評価を困難にする可能性があります。この発見は、将来のより大規模なモデルにおける欺瞞的な行動を予測し、AIの安全性を考慮した評価戦略の設計に役立ちます。


【3】Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13351
📅 2025年09月18日
💡 この論文は、大規模言語モデル（LLM）の構造化されたシンボリックプランニング能力を向上させる新しい手法「PDDL-Instruct」を提案しています。PDDL-Instructは、論理的な思考連鎖を通じて、アクションの適用性、状態遷移、計画の有効性について厳密に推論するようにLLMを訓練します。実験結果では、この手法により、LLMの計画精度が大幅に向上し、標準的なベンチマークで

【4】Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13352
📅 2025年09月18日
💡 この論文は、LLM（大規模言語モデル）を活用した自律型UAV（無人航空機）フレームワーク「Agentic UAVs」を紹介しています。このフレームワークは、LLMによる推論、ツール呼び出し、データベースクエリ、およびサードパーティシステムとの統合を可能にし、動的で不確実なミッションへの適応性を向上させます。シミュレーションされた捜索救助シナリオにおいて、Agentic UAVsは従来の

【5】$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13368
📅 2025年09月18日
💡 この論文は、$Agent^2$という、LLMを活用した自己生成型エージェントフレームワークを紹介しています。$Agent^2$は、自然言語でのタスク記述から、人間による介入なしに、高性能な強化学習エージェントを自動生成します。二重エージェント構造を採用し、タスク分析とエージェント生成を行うGenerator Agentと、生成されたRLエージェントであるTarget Agentで構成されています。様々なベンチマークで手

【6】From Next Token Prediction to (STRIPS) World Models -- Preliminary Results (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13389
📅 2025年09月18日
💡 この論文は、深層学習アーキテクチャ（Transformer）と勾配降下法を用いて、行動の痕跡から命題STRIPS世界モデルを学習する問題を検討しています。このタスクは、トークンがアクションである教師ありの次のトークン予測問題として捉えられています。研究者たちは、適切なTransformerアーキテクチャが命題STRIPS世界モデルを忠実に表現できることを示し、ランダムな有効（肯定）および無効（

【7】SteeringControl: Holistic Evaluation of Alignment Steering in LLMs (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13450
📅 2025年09月18日
💡 この論文は、大規模言語モデル（LLM）におけるアライメント（調整）手法を包括的に評価するための新しいベンチマーク「SteeringControl」を紹介しています。このベンチマークは、バイアス、有害な生成、ハルシネーションといった主要なアライメント目標と、追従性や常識的な道徳といった二次的な行動への影響を評価します。研究の結果、最適なアライメント手法はモデル、手法、ターゲットとする行動の組み合わせ

【8】AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13547
📅 2025年09月18日
💡 この研究では、LLMエージェントに人間が使用するような協調ツールと自律性を持たせることで、問題解決能力が向上するかを検証しました。Claude Codeエージェントにソーシャルメディアとジャーナリングツールを付与した結果、難しいプログラミング課題においてパフォーマンスが大幅に向上し、コスト削減、ターン数減少、完了時間の短縮が見られました。異なるモデルは、問題の難易度に応じて異なる協調戦略を自然

【9】Programmable Cognitive Bias in Social Agents (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13588
📅 2025年09月18日
💡 この論文は、大規模言語モデル（LLM）を用いた社会シミュレーションにおいて、エージェントの行動を体系的に指定するための新しいツールキット「CoBRA」を紹介しています。CoBRAは、従来の自然言語記述による行動指定の課題を解決し、古典的な社会科学実験に基づき、エージェントの認知バイアスを明示的にプログラムします。具体的には、認知バイアスを測定する「認知バイアスインデックス」と、行動を調整する「

【10】InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2509.13704
📅 2025年09月18日
💡 この論文は、データセンターなどのミッションクリティカルな産業インフラの管理を自動化するための新しいGUIエージェントフレームワーク「InfraMind」を提案しています。InfraMindは、複雑なGUIの理解、高精度なタスク実行、状態の特定、効率的な展開、安全性の確保といった、既存のLLMベースのGUIエージェントが抱える課題を解決するために、5つの革新的なモジュールを統合しています。実験結果

---
合計 88 件のAI関連ニュースが見つかりました。