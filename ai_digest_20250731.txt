🤖 AI最新ニュースダイジェスト 🤖
2025年07月31日 12:59

【1】When Truthful Representations Flip Under Deceptive Instructions? (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22149
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）が、悪意のある指示に従って嘘をつく際に、内部表現がどのように変化するかを調査しています。研究者たちは、Llama-3.1-8B-InstructとGemma-2-9B-Instructの内部表現を分析し、嘘をつく指示が、正直な指示や中立的な指示と比較して、モデルの表現に大きな変化を引き起こすことを発見しました。具体的には、嘘

【2】CoEx -- Co-evolving World-model and Exploration (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22281
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）をエージェントの内部世界モデルとして利用する際に生じる、世界モデルの静的性による問題に対処しています。CoExと呼ばれる新しい階層型エージェントアーキテクチャを提案し、LLMの計画と動的に更新される世界モデルを共進化させることで、より正確な計画と探索を実現します。CoExは、テキスト推論とコードベースのシンボリックメモリを組み合わせた

【3】An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22326
📅 2025年07月31日
💡 この論文は、メタバースサービスエコシステムにおけるLLM（大規模言語モデル）を活用したエージェント向けに、説明可能な感情調整フレームワークを提案しています。このフレームワークは、エージェントの意思決定に事実情報を統合し、仮想世界と現実世界のサービスを繋ぐことを目指しています。これにより、キャラクターデータの融合、知識の関連付け、倫理的な安全性の課題を解決し、より現実的な社会的な振る舞いを実現します。オフ

【4】LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22359
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）の能力評価における新たな手法「LLM-Crowdsourced」を提案しています。既存の評価方法が抱える課題を解決するため、LLM自身が質問生成、回答、相互評価を行うことで、動的、透明性、客観性、専門性を兼ね備えた評価を実現します。実験結果は、この手法がLLMの性能を区別し、従来の評価方法では見つけにくい新たな発見

【5】MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22606
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）を活用したマルチエージェントシステムを自動生成する「MetaAgent」というフレームワークを提案しています。MetaAgentは、有限状態機械（FSM）に基づいており、タスクの説明からマルチエージェントシステムを設計し、最適化アルゴリズムで洗練させます。これにより、人間が設計したシステムに匹敵するパフォーマンスを達成し、既存の自動設計方法の限界を克服します。MetaAgent

【6】Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22619
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）とコンテキスト認識プロンプティングを組み合わせることで、製造業における知識へのアクセスを向上させる方法を研究しています。LLMは、自然言語の質問を複雑なSPARQLクエリに変換し、知識グラフ（KG）から情報を取得するのに役立ちます。研究では、KGのスキーマから適切なコンテキストをLLMに提供することで、クエリ生成の精度が大幅に向上することが示

【7】The Incomplete Bridge: How AI Research (Mis)Engages with Psychology (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22847
📅 2025年07月31日
💡 この論文は、AI研究と心理学の相互作用を分析し、AI研究が心理学をどのように利用しているかを調査しています。2023年から2025年の主要なAI論文を分析し、心理学の理論や方法論の利用状況を評価しています。研究では、心理学のどの分野が頻繁に参照されているか、誤った適用例、そしてより効果的な統合のためのガイダンスが示されています。この研究は、AIと

【8】Automatically discovering heuristics in a complex SAT solver with large language models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22876
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）を用いて複雑なSATソルバーのヒューリスティックを自動的に発見する新しい手法「AutoModSAT」を提案しています。AutoModSATは、LLMとの互換性を高めるソルバー設計、自動プロンプト最適化、効率的な探索戦略を組み合わせ、既存のソルバーを大幅に上回る性能向上を実現しました。実験結果では、ベースラインソルバーに対して50%の性能向上、

【9】RedCoder: Automated Multi-Turn Red Teaming for Code LLMs (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22063
📅 2025年07月31日
💡 この論文では、コード生成LLMの脆弱性を発見するための自動化された多段階レッドチーム手法「RedCoder」を紹介しています。RedCoderは、複数のエージェントによる対話シミュレーションから学習し、対話形式で脆弱なコードを生成するようにコードLLMを誘導します。実験結果は、RedCoderが既存の手法よりも効果的に脆弱性を誘発することを示し、コード生成システムのセキュリティ評価を向上させる可能性を示唆しています。これにより、AI

【10】Fuzzing: Randomness? Reasoning! Efficient Directed Fuzzing via Large Language Models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.22065
📅 2025年07月31日
💡 この論文は、大規模言語モデル（LLM）を活用して、ファジングの効率を大幅に向上させる新しい手法「RandLuzz」を提案しています。従来のファジングはランダム性に依存するため効率が低いという課題に対し、RandLuzzはLLMの推論能力とコード生成能力を用いて、より効果的なシード生成とバグ特化型のミューテーター構築を実現します。実験結果では、RandLuzzは既存のファジング手法と比較

---
合計 80 件のAI関連ニュースが見つかりました。