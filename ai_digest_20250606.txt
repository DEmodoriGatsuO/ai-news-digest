🤖 AI最新ニュースダイジェスト 🤖
2025年06月06日 12:55

【1】Contextual Integrity in LLMs via Reasoning and Reinforcement Learning (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04245
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）における文脈的完全性（CI）を向上させるための新しいアプローチを提案しています。具体的には、LLMにCIについて明示的に推論させ、さらに強化学習（RL）フレームワークを用いてCIに必要な推論能力を強化しています。少数の合成データセットで訓練したにも関わらず、この手法は不適切な情報開示を大幅に削減し、既存のCIベンチマークでも性能

【2】Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04251
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）をマルチエージェント強化学習（MARL）に統合した統一フレームワークLLM-MARLを提案しています。LLM-MARLは、コーディネーター、コミュニケーター、メモリの3つのモジュールで構成され、シミュレーション環境におけるエージェント間の協調、コミュニケーション、一般化能力を向上させます。Google Research Football、MAgent Battle、StarCraft IIなどのゲーム環境での

【3】A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04252
📅 2025年06月06日
💡 この論文は、循環経済における意思決定を強化するために、大規模言語モデル（LLM）に特化した「CircuGraphRAG」という新しいフレームワークを紹介しています。CircuGraphRAGは、LLMの出力を、産業コードや排出量データを含む専門知識グラフと連携させることで、情報の正確性と信頼性を向上させます。その結果、単一および複数ステップの質問応答において、従来のLLMやRAG手法よりも優れたパフォーマンスを発揮し

【4】HADA: Human-AI Agent Decision Alignment Architecture (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04253
📅 2025年06月06日
💡 HADAは、LLMエージェントと従来のアルゴリズムを組織の目標と価値観に沿って調整するための、プロトコルとフレームワークに依存しないアーキテクチャです。ビジネス、データサイエンス、監査、倫理、顧客など、役割特化のステークホルダーエージェントが、技術者と非技術者の両方が意思決定をクエリ、制御、監査、または異議申し立てできるように、会話型APIを公開します。

【5】Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04287
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）エージェントが環境内で必要なスキルを獲得するための新しい自動スキル発見フレームワーク「EXIF」を提案しています。EXIFは、探索エージェント（Alice）が環境と対話し、ターゲットエージェント（Bob）の学習に利用する現実的なスキルデータセットを生成します。さらに、AliceはBobのパフォーマンスを評価し、改善点を特定することで、反復的なフィードバックループを形成し、

【6】Plugging Schema Graph into Multi-Table QA: A Human-Guided Framework for Reducing LLM Reliance (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04427
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）を用いた複数テーブルの質問応答（QA）における課題を解決する新しいフレームワークを提案しています。複雑なテーブル間のスキーマリンクの信頼性不足を、人間が作成した関係知識をグラフ構造に組み込むことで克服し、解釈可能な推論チェーンを構築します。これにより、既存手法が苦手とする複雑な実世界のデータセットでも高い精度を実現し、LLMへの依存を減らすことに成功しています

【7】Matching Markets Meet LLMs: Algorithmic Reasoning with Ranked Preferences (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04478
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）が、資源配分やライドシェアリングなどのマッチング市場におけるランキングされた選好を処理する能力を評価しています。研究者たちは、LLMが安定したマッチングの生成、不安定性の検出、解決、そして詳細な選好に関する質問など、様々なタスクで苦戦していることを発見しました。特に、大規模な市場では、LLMは不安定性を解決し、アルゴリズムを反復的に実行

【8】CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04481
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）の数学的能力を人間の認知プロセスに基づき評価する新しいフレームワーク「CogMath」を提案しています。従来の評価方法では見過ごされていた、問題理解、問題解決、解決策の要約という3つの段階に焦点を当て、9つの評価軸でLLMの真の能力を詳細に分析します。CogMathを用いた評価により、主要なLLMの数学能力が過大評価されていることが明らかになり、

【9】"Don't Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04500
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）を用いて、ロボットナビゲーションにおける制約を生成する新しいフレームワーク「STPR」を提案しています。STPRは、LLMのコーディング能力を活用して、自然言語で表現された制約（「何をしてはいけないか」など）をPython関数に変換し、計画アルゴリズムに渡します。これにより、複雑な推論を回避し、幻覚のリスクを軽減しながら、正確な

【10】Schema Generation for Large Knowledge Graphs Using Large Language Models (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2506.04512
📅 2025年06月06日
💡 この論文は、大規模言語モデル（LLM）を活用して、知識グラフ（KG）のスキーマを自動生成する新しい手法を提案しています。従来のスキーマ作成における専門家の負担を軽減するため、LLMがKGのローカルおよびグローバル情報を利用して、Shape Expressions（ShEx）形式のスキーマを生成します。YAGO SchemaとWikidata EntitySchemaという2つの新しいデータセットと評価指標を導入し、LLMのスキーマ生成能力

---
合計 151 件のAI関連ニュースが見つかりました。