🤖 AI最新ニュースダイジェスト 🤖
2025年07月04日 12:53

【1】STELLA: Self-Evolving LLM Agent for Biomedical Research (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02004
📅 2025年07月04日
💡 この論文は、生物医学研究向けの自己進化型AIエージェント「STELLA」を紹介しています。STELLAは、推論戦略のテンプレートライブラリと、新しいツールを自動的に発見・統合するツール作成エージェントを備えた動的なツールオーシャンを通じて、自律的に能力を向上させます。STELLAは、既存のモデルを上回り、経験を通じてパフォーマンスを向上させ、生物医学ベンチマークで高い精度を達成しました。この自己

【2】Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02076
📅 2025年07月04日
💡 この論文は、大規模言語モデル（LLM）の推論効率を向上させるための、テスト時の計算量（TTC）戦略を包括的にレビューしています。論文は、固定計算量で動作する「L1-controllability」と、入力の難易度に応じて計算量を動的に調整する「L2-adaptiveness」という2つの主要なアプローチを提示しています。様々なデータセットで主要なLLMをベンチマークし、推論

【3】Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02083
📅 2025年07月04日
💡 この論文は、大規模言語モデル（LLM）の科学的能力を評価するための新しいベンチマーク「SciGym」を紹介しています。SciGymは、生物学における実験設計と結果解釈能力を、シミュレーションされた生物学的システム（ドライラボ）を用いて評価します。評価の結果、より高性能なLLMは優れたパフォーマンスを示しましたが、システムの複雑さが増すと全てのモデルの性能が低下し、LLMの科学的能力にはまだ大きな改善の余地があることが

【4】Data Diversification Methods In Alignment Enhance Math Performance In LLMs (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02173
📅 2025年07月04日
💡 この論文は、LLMの数学的推論能力を向上させるために、多様なデータ生成手法を検討しています。研究では、温度サンプリング、Chain-of-Thought、モンテカルロ木探索（MCTS）などの手法を評価し、問題解決パスを多様化する新しいアプローチ「Diversified-ThinkSolve (DTS)」を提案しています。その結果、DTSはわずかな計算コスト増で、GSM8Kで7.1

【5】Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02197
📅 2025年07月04日
💡 この論文は、大規模言語モデル（LLM）をロールプレイングエージェントとして使用する際の、信念と行動の一貫性を検証しています。研究では、LLMが人間の行動をシミュレーションする際に、表明した信念と実際の行動がどれだけ一致するのかを評価し、一貫性の欠如を発見しました。この結果は、LLMのシミュレーション結果を人間の行動研究に利用する際に、モデルの信念と行動の整合性を

【6】Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02253
📅 2025年07月04日
💡 この論文は、大規模言語モデル（LLM）の計画能力を向上させるための新しいシステム「NL2FLOW」を紹介しています。NL2FLOWは、自然言語で表現された計画問題を自動的に生成し、生成された計画の品質を厳密に評価します。実験の結果、LLMは特定の条件下で高い成功率で有効な計画を生成できることが示されましたが、中間的な翻訳ステップはパフォーマンスを低下させる可能性があることも判明しました。この研究は、

【7】OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02353
📅 2025年07月04日
💡 この論文は、LLM（大規模言語モデル）を活用した広告キーワード生成フレームワーク「OMS」を提案しています。OMSは、事前の学習データなしで、オンラインでのパフォーマンスをリアルタイムに監視・最適化し、複数の指標に基づいてキーワードを生成します。さらに、自己評価機能も備えており、生成されたキーワードの品質を向上させます。実験結果は、OMSが既存の手法を上回り、広告キャンペーンの成功に貢献する可能性を示唆しています

【8】Clarifying Before Reasoning: A Coq Prover with Structural Context (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02541
📅 2025年07月04日
💡 この論文は、大規模言語モデル（LLM）の推論能力を向上させるために、タスクの明確さを高めることに焦点を当てています。Coq定理証明において、構造化された意味的コンテキストをLLMの入力に追加することで、タスクの明確さを示す指標が大幅に向上し、証明成功率も2倍以上向上しました。このアプローチは、既存の最先端技術を上回り、より小さなモデルのファインチューニングによって

【9】DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02616
📅 2025年07月04日
💡 この論文は、医療におけるインタラクティブでオープンエンドな意思決定のための新しいAIフレームワーク「DynamiCare」を紹介しています。DynamiCareは、LLMを活用した専門家エージェントのチームが、患者システムと対話しながら診断を進める多段階のプロセスを模倣しています。MIMIC-III電子医療記録から構築された「MIMIC-Patient」データセットを使用し、動的な臨床意思決定のベンチマークを確立しました。

【10】Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory (cs.AI updates on arXiv.org)
🔗 https://arxiv.org/abs/2507.02618
📅 2025年07月04日
💡 この論文は、大規模言語モデル（LLM）が競争的な状況下で戦略的思考能力を持つことを、反復囚人のジレンマ（IPD）ゲームを用いた実験で示しています。OpenAI、Google、AnthropicのLLMを古典的な戦略と対戦させた結果、LLMは高い競争力を示し、各モデルは異なる戦略的特徴（Googleは攻撃的、OpenAIは協調的、Anthropicは寛容）を示しました。

---
合計 71 件のAI関連ニュースが見つかりました。